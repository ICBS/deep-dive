{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project you are given a file that contains some parking ticket violations for NYC.\n",
    "\n",
    "(It's just a tiny extract!)\n",
    "\n",
    "If you're wondering where I get these data sets, Kaggle is an **excellent** source of data sets in a whole variety of topics: \n",
    "https://www.kaggle.com/\n",
    "\n",
    "You have to sign up, but it's free.\n",
    "\n",
    "If you want the full data set, it's available here: https://www.kaggle.com/new-york-city/nyc-parking-tickets/version/2#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this sample data set, the file is named: \n",
    "```\n",
    "nyc_parking_tickets_extract.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goals are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Goal 1\n",
    "Create a lazy iterator that will return a named tuple of the data in each row. The data types should be appropriate - i.e. if the column is a date, you should be storing dates in the named tuple, if the field is an integer, then it should be stored as an integer, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Goal 2\n",
    "\n",
    "Calculate the number of violations by car make."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note:\n",
    "Try to use lazy evaluation as much as possible - it may not always be possible though! That's OK, as long as it's kept to a minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, Counter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'nyc_parking_tickets_extract.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_dtype(string):\n",
    "    try:\n",
    "        int(string)\n",
    "        return int\n",
    "    except ValueError:\n",
    "        try:\n",
    "            float(string)\n",
    "            return float\n",
    "        except ValueError:\n",
    "            try:\n",
    "                datetime.strptime(string, '%m/%d/%Y')\n",
    "                return lambda x: datetime.strptime(x, '%m/%d/%Y').date()\n",
    "            except ValueError:\n",
    "                return str\n",
    "def safe_parse(parser, val_str):\n",
    "    try:\n",
    "        return parser(val_str)\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsed_data(file_name):\n",
    "    with open(file_name) as f:\n",
    "        fieldnames = ['_'.join(fieldname.split()) for fieldname in f.readline().lower().split(',')]\n",
    "        Ticket = namedtuple('Ticket', fieldnames, rename=True)\n",
    "        first_row_values_str = [value.strip() for value in f.readline().split(',')]\n",
    "        dtype_parsers = [determine_dtype(string) for string in first_row_values_str]\n",
    "        first_row_parsed = Ticket(*[safe_parse(parser, val_str) for val_str, parser in zip(first_row_values_str, dtype_parsers)])\n",
    "        yield first_row_parsed\n",
    "        for row in f.readlines():\n",
    "            row_values_str = [value.strip() for value in row.split(',')]\n",
    "            yield Ticket(*[safe_parse(parser, val_str) for val_str, parser in zip(row_values_str, dtype_parsers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticket(summons_number=4006478550, plate_id='VAD7274', registration_state='VA', plate_type='PAS', issue_date=datetime.date(2016, 10, 5), violation_code=5, vehicle_body_type='4D', vehicle_make='BMW', violation_description='BUS LANE VIOLATION')\n",
      "Ticket(summons_number=4006462396, plate_id='22834JK', registration_state='NY', plate_type='COM', issue_date=datetime.date(2016, 9, 30), violation_code=5, vehicle_body_type='VAN', vehicle_make='CHEVR', violation_description='BUS LANE VIOLATION')\n",
      "Ticket(summons_number=4007117810, plate_id='21791MG', registration_state='NY', plate_type='COM', issue_date=datetime.date(2017, 4, 10), violation_code=5, vehicle_body_type='VAN', vehicle_make='DODGE', violation_description='BUS LANE VIOLATION')\n",
      "Ticket(summons_number=4006265037, plate_id='FZX9232', registration_state='NY', plate_type='PAS', issue_date=datetime.date(2016, 8, 23), violation_code=5, vehicle_body_type='SUBN', vehicle_make='FORD', violation_description='BUS LANE VIOLATION')\n",
      "Ticket(summons_number=4006535600, plate_id='N203399C', registration_state='NY', plate_type='OMT', issue_date=datetime.date(2016, 10, 19), violation_code=5, vehicle_body_type='SUBN', vehicle_make='FORD', violation_description='BUS LANE VIOLATION')\n"
     ]
    }
   ],
   "source": [
    "parsed_rows = parsed_data(file_name)\n",
    "for _ in range(5):\n",
    "    print(next(parsed_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TOYOT': 112,\n",
       " 'HONDA': 106,\n",
       " 'FORD': 104,\n",
       " 'CHEVR': 76,\n",
       " 'NISSA': 70,\n",
       " 'DODGE': 45,\n",
       " 'FRUEH': 44,\n",
       " 'ME/BE': 38,\n",
       " 'GMC': 35,\n",
       " 'HYUND': 35,\n",
       " 'BMW': 34,\n",
       " 'LEXUS': 26,\n",
       " 'INTER': 25,\n",
       " 'JEEP': 22,\n",
       " 'NS/OT': 18,\n",
       " 'SUBAR': 18,\n",
       " 'INFIN': 13,\n",
       " 'LINCO': 12,\n",
       " 'CHRYS': 12,\n",
       " 'ACURA': 12,\n",
       " 'AUDI': 12,\n",
       " 'VOLVO': 12,\n",
       " 'MITSU': 11,\n",
       " 'ISUZU': 10,\n",
       " 'CADIL': 9,\n",
       " 'KIA': 8,\n",
       " 'VOLKS': 8,\n",
       " 'HIN': 6,\n",
       " 'KENWO': 5,\n",
       " '': 5,\n",
       " 'ROVER': 5,\n",
       " 'BUICK': 5,\n",
       " 'MAZDA': 5,\n",
       " 'MERCU': 4,\n",
       " 'JAGUA': 3,\n",
       " 'SMART': 3,\n",
       " 'PORSC': 3,\n",
       " 'WORKH': 2,\n",
       " 'SATUR': 2,\n",
       " 'SCION': 2,\n",
       " 'SAAB': 2,\n",
       " 'HINO': 2,\n",
       " 'FIR': 1,\n",
       " 'OLDSM': 1,\n",
       " 'PETER': 1,\n",
       " 'CITRO': 1,\n",
       " 'GEO': 1,\n",
       " 'YAMAH': 1,\n",
       " 'BSA': 1,\n",
       " 'MINI': 1,\n",
       " 'PONTI': 1,\n",
       " 'SPRI': 1,\n",
       " 'PLYMO': 1,\n",
       " 'UPS': 1,\n",
       " 'FIAT': 1,\n",
       " 'UD': 1,\n",
       " 'UTILI': 1,\n",
       " 'GMCQ': 1,\n",
       " 'STAR': 1,\n",
       " 'AM/T': 1,\n",
       " 'MI/F': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violation_counts_by_make = lambda : dict(Counter((row.vehicle_make for row in parsed_data(file_name))).most_common())\n",
    "violation_counts_by_make()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
