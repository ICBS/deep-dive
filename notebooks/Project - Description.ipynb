{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project you have 4 files containing information about persons.\n",
    "\n",
    "The files are:\n",
    "* `personal_info.csv` -   personal information such as name, gender, etc. (one row per person)\n",
    "* `vehicles.csv` -   what vehicle people own (one row per person)\n",
    "* `employment.csv` -   where a person is employed (one row per person)\n",
    "* `update_status.csv` -   when the person's data was created and last updated\n",
    "\n",
    "Each file contains a key, `SSN`, which **uniquely** identifies a person.\n",
    "\n",
    "This key is present in **all** four files.\n",
    "\n",
    "You are guaranteed that the same SSN value is present in **every** file, and that it only appears **once per file**.\n",
    "\n",
    "In addition, the files are all sorted by SSN, i.e. the SSN values appear in the same order in each file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Goal 1\n",
    "\n",
    "Your first task is to create iterators for each of the four files that contained cleaned up data, of the correct type (e.g. string, int, date, etc), and represented by a named tuple.\n",
    "\n",
    "For now these four iterators are just separate, independent iterators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Goal 2\n",
    "\n",
    "Create a single iterable that combines all the columns from all the iterators.\n",
    "\n",
    "The iterable should yield named tuples containing all the columns.\n",
    "Make sure that the SSN's across the files match!\n",
    "\n",
    "All the files are guaranteed to be in SSN sort order, and every SSN is unique, and every SSN appears in every file.\n",
    "\n",
    "Make sure the SSN is not repeated 4 times - one time per row is enough!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Goal 3\n",
    "\n",
    "Next, you want to identify any stale records, where stale simply means the record has not been updated since 3/1/2017 (e.g. last update date < 3/1/2017). Create an iterator that only contains current records (i.e. not stale) based on the `last_updated` field from the `status_update` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Goal 4\n",
    "\n",
    "Find the largest group of car makes for each gender.\n",
    "\n",
    "Possibly more than one such group per gender exists (equal sizes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Hints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will not be able to use a simple split approach here, as I explain in the video.\n",
    "\n",
    "Instead you should use the `csv` module and the `reader` function.\n",
    "\n",
    "Here's a simple example of how to use it - you will need to expand on this for your project goals, but this is a good starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def read_file(file_name):\n",
    "    with open(file_name) as f:\n",
    "        rows = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "        yield from rows\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ssn', 'first_name', 'last_name', 'gender', 'language']\n",
      "['100-53-9824', 'Sebastiano', 'Tester', 'Male', 'Icelandic']\n",
      "['101-71-4702', 'Cayla', 'MacDonagh', 'Female', 'Lao']\n",
      "['101-84-0356', 'Nomi', 'Lipprose', 'Female', 'Yiddish']\n",
      "['104-22-0928', 'Justinian', 'Kunzelmann', 'Male', 'Dhivehi']\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "rows = read_file('personal_info.csv')\n",
    "for row in islice(rows, 5):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data is already separated into a list containing the individual fields - but of course they are all just strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, Counter\n",
    "from itertools import groupby\n",
    "from datetime import datetime, timezone\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_personal = 'personal_info.csv'\n",
    "fname_employment = 'employment.csv'\n",
    "fname_vehicles = 'vehicles.csv'\n",
    "fname_update_status = 'update_status.csv'\n",
    "fnames = {'personal_info':fname_personal, 'employment':fname_employment, 'vehicles':fname_vehicles, 'update_status':fname_update_status}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_dtype(string):\n",
    "    try:\n",
    "        int(string)\n",
    "        return int\n",
    "    except ValueError:\n",
    "        try:\n",
    "            float(string)\n",
    "            return float\n",
    "        except ValueError:\n",
    "            try:\n",
    "                datetime.strptime(string, '%Y-%m-%dT%H:%M:%S%z')\n",
    "                return lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%S%z')\n",
    "            except ValueError:\n",
    "                return str\n",
    "\n",
    "def safe_parse(parser, val_str):\n",
    "    if not val_str:\n",
    "        return None\n",
    "    try:\n",
    "        return parser(val_str)\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parsed_data(file_name):\n",
    "    with open(file_name, newline='') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        fieldnames = ['_'.join(fieldname.lower().split()) for fieldname in next(csvreader)]\n",
    "        Record = namedtuple('Record', fieldnames, rename=True)\n",
    "        first_row_values_str = next(csvreader)\n",
    "        dtype_parsers = [determine_dtype(string) for string in first_row_values_str]\n",
    "        first_row_parsed = Record(*[safe_parse(parser, val_str) for val_str, parser in zip(first_row_values_str, dtype_parsers)])\n",
    "        yield first_row_parsed\n",
    "        for row in csvreader:\n",
    "            yield Record(*[safe_parse(parser, val_str) for val_str, parser in zip(row, dtype_parsers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_iters = {table: parsed_data(fname) for table, fname in fnames.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_combined(fnames):\n",
    "    iters_zip = zip(*[parsed_data(fname) for fname in fnames.values()])\n",
    "    merged_record_dict = {k:v for record in next(iters_zip) for k, v in record._asdict().items()}\n",
    "    MergeRecord = namedtuple('MergeRecord', merged_record_dict.keys())\n",
    "    yield MergeRecord(**merged_record_dict)\n",
    "    for records in iters_zip:\n",
    "        yield MergeRecord(**{k:v for record in records for k, v in record._asdict().items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter_combined(fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = datetime(2017, 3, 1,tzinfo=timezone.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_iter_combined(fnames, *, key=lambda x: x.last_updated >= cutoff_date):\n",
    "    yield from filter(key, iter_combined(fnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_records = [*filtered_iter_combined(fnames)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female\n",
      "[('Chevrolet', 42), ('Ford', 42)]\n",
      "Male\n",
      "[('Ford', 40)]\n"
     ]
    }
   ],
   "source": [
    "for key, group in groupby(sorted(filtered_iter_combined(fnames), key=lambda x: x.gender), lambda x: x.gender):\n",
    "    value_counts = Counter(r.vehicle_make for r in group).most_common()\n",
    "    max_count = value_counts[0][1]\n",
    "    print(key)\n",
    "    print([(make, count) for make, count in value_counts if count == max_count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Female\n",
    "[('Chevrolet', 42), ('Ford', 42)]\n",
    "Male\n",
    "[('Ford', 40)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
